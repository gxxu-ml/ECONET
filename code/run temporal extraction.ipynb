{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12ed0c1",
   "metadata": {},
   "source": [
    "# Create Test Data for brave-tin-soldier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4babc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_id</th>\n",
       "      <th>end_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>They were given him for a birthday present , and he stood at the table to set them up .</td>\n",
       "      <td>99</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The soldiers were all exactly alike , excepting one , who had only one leg ; he had been left to the last , and then there was not enough of the melted tin to finish him , so they made him to stand firmly on one leg , and this caused him to be very remarkable . '</td>\n",
       "      <td>119</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2,\"The table on which the tin soldiers stood , was covered with other playthings , but the most attractive to the eye was a pretty little paper castle .</td>\n",
       "      <td>178</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Through the small windows the rooms could be seen .</td>\n",
       "      <td>207</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In front of the castle a number of little trees surrounded a piece of looking - glass , which was intended to represent a transparent lake .</td>\n",
       "      <td>217</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Swans , made of wax , swam on the lake , and were reflected in it .</td>\n",
       "      <td>244</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All this was very pretty , but the prettiest of all was a tiny little lady , who stood at the open door of the castle ; she , also , was made of paper , and she wore a dress of clear muslin , with a narrow blue ribbon over her shoulders just like a scarf .</td>\n",
       "      <td>261</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In front of these was fixed a glittering tinsel rose , as large as her whole face . '</td>\n",
       "      <td>319</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3,\"The little lady was a dancer , and she stretched out both her arms , and raised one of her legs so high , that the tin soldier could not see it at all , and he thought that she , like himself , had only one leg . ' '</td>\n",
       "      <td>338</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                   sentence  \\\n",
       "5                                                                                                                                                                                   They were given him for a birthday present , and he stood at the table to set them up .   \n",
       "6   The soldiers were all exactly alike , excepting one , who had only one leg ; he had been left to the last , and then there was not enough of the melted tin to finish him , so they made him to stand firmly on one leg , and this caused him to be very remarkable . '   \n",
       "7                                                                                                                  2,\"The table on which the tin soldiers stood , was covered with other playthings , but the most attractive to the eye was a pretty little paper castle .   \n",
       "8                                                                                                                                                                                                                       Through the small windows the rooms could be seen .   \n",
       "9                                                                                                                              In front of the castle a number of little trees surrounded a piece of looking - glass , which was intended to represent a transparent lake .   \n",
       "10                                                                                                                                                                                                      Swans , made of wax , swam on the lake , and were reflected in it .   \n",
       "11         All this was very pretty , but the prettiest of all was a tiny little lady , who stood at the open door of the castle ; she , also , was made of paper , and she wore a dress of clear muslin , with a narrow blue ribbon over her shoulders just like a scarf .   \n",
       "12                                                                                                                                                                                    In front of these was fixed a glittering tinsel rose , as large as her whole face . '   \n",
       "13                                              3,\"The little lady was a dancer , and she stretched out both her arms , and raised one of her legs so high , that the tin soldier could not see it at all , and he thought that she , like himself , had only one leg . ' '   \n",
       "\n",
       "    start_id  end_id  \n",
       "5         99     118  \n",
       "6        119     177  \n",
       "7        178     206  \n",
       "8        207     216  \n",
       "9        217     243  \n",
       "10       244     260  \n",
       "11       261     318  \n",
       "12       319     337  \n",
       "13       338     388  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"/home/gxu21/ECONET/code/data_process/FairytaleQA_Dataset/split_by_origin/andersen-fairybook/brave-tin-soldier-story/brave-tin-soldier-story.tokens\"\n",
    "df = pd.read_csv(path, sep=\"\t\")\n",
    "#words is a list of all extracted tokens from the .token file\n",
    "words = list(df[\"word\"])\n",
    "len(words)\n",
    "words_dict = dict()\n",
    "for i,w in enumerate(words):\n",
    "    words_dict[i] = w\n",
    "\n",
    "#split the words into a new df of sentences, which includes their start and end token_pos\n",
    "sentences = []\n",
    "start = []\n",
    "end = []\n",
    "sent = None\n",
    "for i,w in enumerate(words):\n",
    "    if sent == None:\n",
    "        if w == \"\\t\":\n",
    "            sent+= \"'\"\n",
    "        else:\n",
    "            sent = w\n",
    "        start_id =i\n",
    "    else:\n",
    "        if w == \"\\t\":\n",
    "            sent+= \" '\"\n",
    "        else:\n",
    "            sent+= \" \"+ w\n",
    "    if (w == \".\" or w == \"\\t\") and (i+1>=len(words) or words[i+1]!='\\t'):\n",
    "        end_id = i\n",
    "        sentences.append(sent)\n",
    "        start.append(start_id)\n",
    "        end.append(end_id)\n",
    "        sent = None\n",
    "sent_df = pd.DataFrame({\"sentence\":sentences})\n",
    "sent_df[\"start_id\"] = start\n",
    "sent_df[\"end_id\"] = end\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "sent_df= sent_df.iloc[5:14]\n",
    "sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b15201c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigger</th>\n",
       "      <th>v_s</th>\n",
       "      <th>v_e</th>\n",
       "      <th>arg0</th>\n",
       "      <th>a0_s</th>\n",
       "      <th>a0_e</th>\n",
       "      <th>arg1</th>\n",
       "      <th>a1_s</th>\n",
       "      <th>a1_e</th>\n",
       "      <th>arg2</th>\n",
       "      <th>a2_s</th>\n",
       "      <th>a2_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>were</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>were</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exactly alike</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stood</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the tin soldiers</td>\n",
       "      <td>182.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>could</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>surrounded</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>a number of little trees</td>\n",
       "      <td>222.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>a piece of looking - glass , which was intended to represent a transparent lake</td>\n",
       "      <td>228.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>made</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>of wax</td>\n",
       "      <td>247.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>was</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>very pretty</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>was</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>was</td>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a dancer</td>\n",
       "      <td>342.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trigger  v_s  v_e                      arg0   a0_s   a0_e  \\\n",
       "4         were  100  100                       NaN    NaN    NaN   \n",
       "5         were  121  121                       NaN    NaN    NaN   \n",
       "6        stood  185  185                       NaN    NaN    NaN   \n",
       "7        could  213  213                       NaN    NaN    NaN   \n",
       "8   surrounded  227  227  a number of little trees  222.0  226.0   \n",
       "9         made  246  246                       NaN    NaN    NaN   \n",
       "10         was  263  263                       NaN    NaN    NaN   \n",
       "11         was  323  323                       NaN    NaN    NaN   \n",
       "12         was  341  341                       NaN    NaN    NaN   \n",
       "\n",
       "                                                                               arg1  \\\n",
       "4                                                                               NaN   \n",
       "5                                                                               NaN   \n",
       "6                                                                  the tin soldiers   \n",
       "7                                                                               NaN   \n",
       "8   a piece of looking - glass , which was intended to represent a transparent lake   \n",
       "9                                                                               NaN   \n",
       "10                                                                              NaN   \n",
       "11                                                                              NaN   \n",
       "12                                                                              NaN   \n",
       "\n",
       "     a1_s   a1_e           arg2   a2_s   a2_e  \n",
       "4     NaN    NaN            NaN    NaN    NaN  \n",
       "5     0.0    1.0  exactly alike  123.0  124.0  \n",
       "6   182.0  184.0            NaN    0.0    1.0  \n",
       "7     NaN    NaN            NaN    NaN    NaN  \n",
       "8   228.0  242.0            NaN    NaN    NaN  \n",
       "9     0.0    0.0         of wax  247.0  248.0  \n",
       "10    0.0    1.0    very pretty  264.0  265.0  \n",
       "11    NaN    NaN            NaN    NaN    NaN  \n",
       "12    NaN    2.0       a dancer  342.0  343.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('allen_srl_event.csv')\n",
    "df = df.iloc[4:13]\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313e31f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_predicate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     concat \u001b[38;5;241m=\u001b[39m sent_df\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m sent_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     offset = int(sent_df.iloc[i-1][\"start_id\"])\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     l_event, r_event = int(df.iloc[i-1][\"v_s\"]) - offset, int(df.iloc[i][\"v_s\"]) - offset\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     events \u001b[38;5;241m=\u001b[39m \u001b[43mget_predicate\u001b[49m(concat)\n\u001b[1;32m     11\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m events[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     12\u001b[0m     lverb, rverb \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_predicate' is not defined"
     ]
    }
   ],
   "source": [
    "#curate two_sentences pair, + the token position of the verb\n",
    "sent_ls = []\n",
    "event_ids = []\n",
    "verbs = []\n",
    "\n",
    "for i in range(1, df.shape[0]):\n",
    "    concat = sent_df.iloc[i-1][\"sentence\"] + sent_df.iloc[i][\"sentence\"]\n",
    "#     offset = int(sent_df.iloc[i-1][\"start_id\"])\n",
    "#     l_event, r_event = int(df.iloc[i-1][\"v_s\"]) - offset, int(df.iloc[i][\"v_s\"]) - offset\n",
    "    events = get_predicate(concat)\n",
    "    tokens = events[0][-1]\n",
    "    lverb, rverb = df.iloc[i-1][\"trigger\"], df.iloc[i][\"trigger\"]\n",
    "    l_event = tokens.index(lverb)\n",
    "    r_event = l_event + tokens[l_event+1:].index(rverb)+1\n",
    "    \n",
    "    sent_ls.append(concat)\n",
    "    event_ids.append([l_event, r_event])\n",
    "    verbs.append([lverb, rverb])\n",
    "    print(concat)\n",
    "    print(l_event, r_event)\n",
    "    print(lverb,rverb)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b218eff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the triggers: ---------  \n",
      "\n",
      "were were\n",
      "print the triggers: ---------  \n",
      "\n",
      "were stood\n",
      "print the triggers: ---------  \n",
      "\n",
      "stood could\n",
      "print the triggers: ---------  \n",
      "\n",
      "could surrounded\n",
      "print the triggers: ---------  \n",
      "\n",
      "surrounded made\n",
      "print the triggers: ---------  \n",
      "\n",
      "made was\n",
      "print the triggers: ---------  \n",
      "\n",
      "was was\n",
      "print the triggers: ---------  \n",
      "\n",
      "was was\n"
     ]
    }
   ],
   "source": [
    "examples = create_data_instances(sent_ls, event_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c25048a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../data/matres/example.pickle', 'wb') as f:\n",
    "    pickle.dump(examples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab79c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f013f03f",
   "metadata": {},
   "source": [
    "# # Prepare Examples Dataset, save to Pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd454433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = coref-spanbert\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = coref\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = Coreference Resolution\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = coref\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = coref-spanbert-large-2020.02.27.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = coref/coref_spanbert_large.jsonnet\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.description = The basic outline of this model is to get an embedded representation of each span in the document. These span representations are scored  and used to prune away spans that are unlikely to occur in a coreference  cluster. For the remaining spans, the model decides which antecedent span (if any) they are coreferent with. The resulting coreference links, after applying transitivity, imply a clustering of the spans in the document. The GloVe embeddings in the original paper have been substituted with SpanBERT embeddings.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.short_description = Higher-order coref with coarse-to-fine inference (with SpanBERT embeddings).\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.developed_by = Lee et al\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contributed_by = Zhaofeng Wu\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.date = 2020-02-27\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.version = 2\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.model_type = SpanBERT\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Lee2018HigherorderCR,\n",
      "title={Higher-order Coreference Resolution with Coarse-to-fine Inference},\n",
      "author={Kenton Lee and Luheng He and L. Zettlemoyer},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.title = Higher-order Coreference Resolution with Coarse-to-fine Inference\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:4891749\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.model_performance_measures = CoNLL coref scores and Mention Recall\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Ontonotes 5.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.name = Ontonotes 5.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = generation-bart\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = bart\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = BART\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = bart-2020.07.25.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = generation/bart_cnn_dm.jsonnet\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.description = The BART model here uses a language modeling head, and therefore can be used for generation. The BART encoder, implemented as a `Seq2SeqEncoder`, which assumes it operates on already embedded inputs.  This means that we remove the token and position embeddings from BART in this module.  For the typical use case of using BART to encode inputs to your model (where we include the token and position embeddings from BART), you should use `PretrainedTransformerEmbedder(bart_model_name, sub_module=\"encoder\")` instead of this.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.short_description = BART with a language model head for generation.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.developed_by = Lewis et al\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.date = 2020-07-25\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.model_type = BART\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Lewis2020BARTDS,\n",
      "title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},\n",
      "author={M. Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and A. Mohamed and Omer Levy and Ves Stoyanov and L. Zettlemoyer},\n",
      "booktitle={ACL},\n",
      "year={2020}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.title = BART: Denosing Sequence-to-Sequence Pre-training for Natural Language Generation,Translation, and Comprehension\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:204960716\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.model_performance_measures = ROUGE and BLEU\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.name = CNN/DailyMail\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.name = CNN/DailyMail\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = glove-sst\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = GLoVe-LSTM\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = sentiment-analysis\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = basic_stanford_sentiment_treebank-2020.06.09.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = classification/basic_stanford_sentiment_treebank.jsonnet\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.description = This model uses GloVe embeddings and is trained on the binary classification setting of the Stanford Sentiment Treebank. It achieves about 87% on the test set.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.short_description = LSTM binary classifier with GloVe embeddings.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.developed_by = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.date = 2020-06-09\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.model_type = LSTM\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Sentiment Treebank\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.preprocessing = Binary classification setting\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = Accuracy: 87% on SST test set.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = lm-masked-language-model\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = masked_language_model\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = BERT-based Masked Language Model\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = masked-language-modeling\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = bert-masked-lm-2020-10-07.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = lm/bidirectional_language_model.jsonnet\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.description = The `MaskedLanguageModel` embeds some input tokens (including some which are masked), contextualizes them, then predicts targets for the masked tokens, computing a loss against known targets.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.short_description = BERT-based masked language model\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.date = 2020-10-07\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.model_type = BERT\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Devlin2019BERTPO,\n",
      "title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n",
      "author={J. Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.title = BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:52967399\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.model_performance_measures = Perplexity\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.motivation = Document-level corpus is used rather than shuffled sentence-level corpus, to extract long contiguous sequences.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.preprocessing = For Wikipedia, text passages are extracted and lists, tables, and headers are ignored.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = BERT demonstrates gender bias in that it thinks the doctor is more likely a man ('his') than a woman ('her'). An important issue in NLP is how to understand and address such biases in our linguistic models.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = NOTE: This was developed for use in a demo, not for training.  It's possible that it will still work for training a masked LM, but it is very likely that some other code would be much more efficient for that.  This `does` compute correct gradients of the loss, because we use that in our demo, so in principle it should be able to train a model, we just don't necessarily endorse that use.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = lm-next-token-lm-gpt2\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = next_token_lm\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = GPT2-based Next Token Language Model\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = language-modeling\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = gpt2-next-word-lm-2020.06.30.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.description = This is the public 345M parameter OpenAI GPT-2 language model for generating sentences. The model embeds some input tokens, contextualizes them, then predicts the next word, computing a loss against known target. \n",
      "If `BeamSearch` is given, this model will predict a sequence of next tokens.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.short_description = OpenAI's GPT-2 language model that generates the next token.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.developed_by = Radford et al\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.date = 2020-06-30\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.model_type = GPT2\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Radford2019LanguageMA,\n",
      "title={Language Models are Unsupervised Multitask Learners},\n",
      "author={A. Radford and Jeffrey Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},\n",
      "year={2019}}\n",
      "\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.title = Language Models are Unsupervised Multitask Learners\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:160025533\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.model_performance_measures = Perplexity\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.name = WebText corpus\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.name = WebText corpus\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.motivation = WebText emphasizes document quality. Only human-curated/filtered documents are scraped. Reddit outbound links which receive at least 3 karma points are taken as a proxy for human filtered webpages that are interesting.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.preprocessing = Dragnet and [Newspaper](https://github.com/codelucas/newspaper) content extractors are used. Wikipedia articles are removed.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = mc-roberta-commonsenseqa\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = transformer_mc\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = transformer_mc\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = RoBERTa Common Sense QA\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = mc\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = commonsenseqa.2020-07-08.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = mc/commonsenseqa.jsonnet\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa-based multiple choice model for CommonSenseQA.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.developed_by = Liu et al\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.date = 2020-07-08\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa large\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.name = CommonSenseQA (validation set)\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.name = CommonSenseQA (train set)\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = mc-roberta-piqa\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = transformer_mc\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = transformer_mc\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = Physical Interaction Question Answering\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = mc\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = piqa.2020-07-08.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = mc/piqa.jsonnet\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa-based multiple choice model for PIQA.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.date = 2020-07-08\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa large\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.name = PIQA (validation set)\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.name = PIQA (train set)\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = mc-roberta-swag\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = transformer_mc\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = transformer_mc\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = RoBERTa SWAG\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = mc\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = swag.2020-07-08.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = mc/swag.jsonnet\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa-based multiple choice model for SWAG.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.date = 2020-07-08\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa large\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.name = SWAG (validation set)\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://rowanzellers.com/swag/\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.name = SWAG (train set)\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.url = https://rowanzellers.com/swag/\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = pair-classification-decomposable-attention-elmo\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = decomposable_attention\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = textual_entailment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = ELMo-based Decomposable Attention\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = textual_entailment\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = decomposable-attention-elmo-2020.04.09.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = decomposable_attention_elmo.jsonnet\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.description = This `Model` implements the Decomposable Attention model described in [A Decomposable Attention Model for Natural Language Inference](https://api.semanticscholar.org/CorpusID:8495258) by Parikh et al., 2016, with some optional enhancements before the decomposable attention actually happens.  Parikh's original model allowed for computing an \"intra-sentence\" attention before doing the decomposable entailment step.  We generalize this to any `Seq2SeqEncoder` that can be applied to the premise and/or the hypothesis before computing entailment.\n",
      "\n",
      "The basic outline of this model is to get an embedded representation of each word in thepremise and hypothesis, align words between the two, compare the aligned phrases, and make a final entailment decision based on this aggregated comparison.  Each step in this process uses a feedforward network to modify the representation.\n",
      "\n",
      "This model uses ELMo embeddings.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.short_description = The decomposable attention model (Parikh et al, 2017) combined with ELMo embeddings trained on SNLI.\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.developed_by = Parikh et al\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.date = 2020-04-09\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.model_type = Seq2Seq\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Parikh2016ADA,\n",
      "title={A Decomposable Attention Model for Natural Language Inference},\n",
      "author={Ankur P. Parikh and Oscar T{\"a}ckstr{\"o}m and Dipanjan Das and Jakob Uszkoreit},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1606.01933}}\n",
      "\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.title = A Decomposable Attention Model for Natural Language Inference\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:8495258\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   id = pair-classification-esim\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_model_name = esim\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   registered_predictor_name = textual_entailment\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   display_name = Enhanced LSTM for Natural Language Inference\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   task_id = textual_entailment\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.archive_file = esim-elmo-2020.11.11.tar.gz\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.training_config = esim.jsonnet\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:55 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This `Model` implements the ESIM model, which is a sequential neural inference model based on chain LSTMs.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = Enhanced LSTM trained on SNLI.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Chen et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-04-09\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = LSTM\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Chen2017EnhancedLF,\n",
      "title={Enhanced LSTM for Natural Language Inference},\n",
      "author={Qian Chen and Xiao-Dan Zhu and Z. Ling and Si Wei and Hui Jiang and Diana Inkpen},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Enhanced LSTM for Natural Language Inference\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:34032948\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = pair-classification-roberta-mnli\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = basic_classifier\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = textual_entailment\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = RoBERTa MNLI\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = textual_entailment\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = mnli-roberta-2020-07-29.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = pair_classification/mnli_roberta.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa finetuned on MNLI.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Liu et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-07-29\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) dev set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_dev_mismatched.jsonl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) train set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_train.jsonl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = pair-classification-roberta-snli\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = basic_classifier\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = textual_entailment\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = RoBERTa SNLI\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = textual_entailment\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = snli-roberta-2020-07-29.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = pair_classification/snli_roberta.jsonnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa finetuned on SNLI.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Liu et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-07-29\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = rc-bidaf-elmo\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = bidaf\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = ELMo-BiDAF\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = bidaf-elmo.2021-02-11.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = rc/bidaf_elmo.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This is an implementation of the BiDAF model with ELMo embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = BiDAF model with ELMo embeddings instead of GloVe.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Seo et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-03-19\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = BiDAF\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Start, end and overall span accuracy, Exact Match, F1 score\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = SQuAD dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = SQuAD training set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 66%\n",
      "End accuracy: 69%\n",
      "Overall span accuracy: 57%\n",
      "Exact match: 71%\n",
      "F1: 80%\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = rc-bidaf\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = bidaf\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = BiDAF\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = bidaf-model-2020.03.19.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = rc/bidaf.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This is an implementation of the BiDAF model with GloVe embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = BiDAF model with GloVe embeddings.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Seo et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-03-19\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = BiDAF\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Start, end, and overall span accuracy, Exact Match, F1 score\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = SQuAD dev set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = SQuAD training set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 61%\n",
      "End accuracy: 66%\n",
      "Overall span accuracy: 52%\n",
      "Exact match: 66%\n",
      "F1: 76%\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = rc-naqanet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = naqanet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Numerically Augmented QA Net\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = naqanet-2020.02.19.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = rc/naqanet.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = An augmented version of QANet model with some rudimentary numerical reasoning abilities. The main idea here is that instead of just predicting a passage span after doing all of the QANet modeling stuff, we add several different 'answer abilities': predicting a span from the question, predicting a count, or predicting an arithmetic expression.  Near the end of the QANet model, we have a variable that predicts what kind of answer type we need, and each branch has separate modeling logic to predict that answer type.  We then marginalize over all possible ways of getting to the right answer through each of these answer types.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = An augmented version of QANet that adds rudimentary numerical reasoning ability, trained on DROP (Dua et al., 2019), as published in the original DROP paper.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Dua et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-02-19\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = QANet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Dua2019DROPAR,\n",
      "title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n",
      "author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:67855846\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Exact Match and F1-score\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = DROP\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_dev.json\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://allennlp.org/drop\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = DROP\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_train.json\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://allennlp.org/drop\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = rc-nmn\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Neural Module Network (NMN)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = drop-nmn-2020.04.04.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = A neural module network trained on DROP.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = A neural module network trained on DROP.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Andreas et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-04-04\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = Neural Module Network\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Andreas2016NeuralMN,\n",
      "title={Neural Module Networks},\n",
      "author={Jacob Andreas and Marcus Rohrbach and Trevor Darrell and D. Klein},\n",
      "journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
      "year={2016},\n",
      "pages={39-48}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Neural Module Networks\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:5276660\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = DROP\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://allennlp.org/drop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = rc-transformer-qa\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = transformer_qa\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Transformer QA\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = transformer-qa.2021-02-11.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = rc/transformer_qa.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = The model implements a reading comprehension model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), with improvements borrowed from the SQuAD model in the transformers project. It predicts start tokens and end tokens with a linear layer on top of word piece embeddings.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = A reading comprehension model patterned after the proposed model in Devlin et al, with improvements borrowed from the SQuAD model in the transformers project\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld and Evan Pete Walsh\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-10-03\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 2\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = F1-score, Span Accuracy, Exact Match\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = SQuAD dev set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v2.0.json\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = SQuAD training set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v2.0.json\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = For the pretrained RoBERTa model, document-level corpora were used rather than a shuffled sentence-level corpus such as the Billion Word Benchmark (Chelba et al., 2013) in order to extract long contiguous sequences\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = For the pretrained RoBERTa model, only the text passages were extracted from English Wikipedia; lists, tables, and headers were ignored.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 88%\n",
      "Exact match: 84%\n",
      "These are metrics using the official evaluation. Note that the metrics that the model produces while training are calculated on a per-instance basis only. Since there could be more than one instance per question, these metrics are not the official numbers on the SQuAD task. To get official numbers, run the evaluation script at allennlp_models/rc/tools/transformer_qa_eval.py.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = roberta-sst\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = RoBERTa large\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = sentiment-analysis\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = sst-roberta-large-2020.06.08.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = classification/stanford_sentiment_treebank_roberta.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This model is trained on RoBERTa large with the binary classification setting of the Stanford Sentiment Treebank. It achieves 95.11% accuracy on the test set.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa-based binary classifier for Stanford Sentiment Treebank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = Zhaofeng Wu\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-06-08\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa large\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Sentiment Treebank\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = Binary classification setting\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = Accuracy: 95.11% on SST test set.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = semparse-nlvr\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = NLVR Semantic Parsing\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = semparse-nlvr\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/nlvr-erm-model-2020.02.10-rule-vocabulary-updated.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = The model is a semantic parser trained on Cornell NLVR.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = The model is a semantic parser trained on Cornell NLVR.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Dasigi et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Denotation accuracy and consistency\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Cornell NLVR\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = Cornell NLVR\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = semparse-text-to-sql\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Text to SQL (ATIS)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = semparse-text-to-sql\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/atis-parser-2020.02.10.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset. This model is still a proof-of-concept of what you can do with semantic parsing in AllenNLP and its performance is not state-of-the-art (this naive model gets around 40% exact denotation accuracy on the contextual ATIS dataset).\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Dasigi et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-02-10\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = 1. `exact_match`; the percentage of the time that our best output action sequence matches the SQL query exactly.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `valid_sql_query`; the percentage of time that decoding actually produces avalid SQL query.\n",
      "4. `action_similarity`; how similar the action sequence predicted is to the actual action sequence.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = ATIS\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = ATIS\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = semparse-wikitables\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = WikiTables Semantic Parsing\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = semparse-tabular\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = wikitables-model-2020.02.10.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Dasigi et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-02-10\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = 1. `lf_retrieval_acc`; the percentage of the time that our best output action sequence is in the set of action sequences provided by offline search.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `lf_percent`; the percentage of time that decoding actually produces a finished logical form\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = WikiTableQuestions\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = WikiTableQuestions\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = structured-prediction-biaffine-parser\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = biaffine_parser\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Deep Biaffine Attention for Neural Dependency Parsing\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = dependency-parsing\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = biaffine-dependency-parser-ptb-2020.04.06.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = structured_prediction/dependency_parser.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This dependency parser follows the model of [Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)](https://api.semanticscholar.org/CorpusID:7942973) .\n",
      "\n",
      "Word representations are generated using a bidirectional LSTM, followed by separate biaffine classifiers for pairs of words, predicting whether a directed arc exists between the two words and the dependency label the arc should have. Decoding can either be done greedily, or the optimal Minimum Spanning Tree can be decoded using Edmond's algorithm by viewing the dependency tree as a MST on a fully connected graph, where nodes are words and edges are scored dependency arcs.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = A neural model for dependency parsing using biaffine classifiers on top of a bidirectional LSTM.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Dozat et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-04-06\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Dozat2017DeepBA,\n",
      "title={Deep Biaffine Attention for Neural Dependency Parsing},\n",
      "author={Timothy Dozat and Christopher D. Manning},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01734}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:7942973\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Attachment scores and exact matches (UAS, LAS, UEM, LEM)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = PTB 3.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = PTB 3.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = The parser achieves 95.57% and 94.44% unlabeled and labeled attachement score using gold POS tags. For predicted POS tags, it achieves 94.81% UAS and 92.86% LAS respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = structured-prediction-constituency-parser\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = constituency_parser\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Constituency Parser with ELMo embeddings\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = constituency-parsing\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = elmo-constituency-parser-2020.02.10.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = structured-prediction/constituency_parser_elmo.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This is an implementation of a minimal neural model for constituency parsing based on an independent scoring of labels and spans. This `SpanConstituencyParser` simply encodes a sequence of text with a stacked `Seq2SeqEncoder`, extracts span representations using a `SpanExtractor`, and then predicts a label for each span in the sequence. These labels are non-terminal nodes in a constituency parse tree, which we then greedily reconstruct. The model uses ELMo embeddings, which are completely character-based and improves single model performance from 92.6 F1 to 94.11 F1 on the Penn Treebank, a 20% relative error reduction.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = Constituency parser with character-based ELMo embeddings\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Joshi et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-02-10\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = Seq2SeqEncoder\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Joshi2018ExtendingAP,\n",
      "title={Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples},\n",
      "author={V. Joshi and Matthew E. Peters and Mark Hopkins},\n",
      "booktitle={ACL},\n",
      "year={2018}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:21712653\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Precision, Recall and F1-score for parse trees (EVALB_bracketing_scorer)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = PTB 3.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = PTB 3.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = 94.11 F1 score\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = structured-prediction-srl-bert\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = srl_bert\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = SRL BERT\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = srl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = structured-prediction-srl-bert.2020.12.15.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = structured_prediction/bert_base_srl.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = An implementation of a BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer), which is currently the state of the art single model for English PropBank SRL (Newswire sentences). It achieves 86.49 test F1 on the Ontonotes 5.0 dataset.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = A BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Shi et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-09-03\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = BERT\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Shi2019SimpleBM,\n",
      "title={Simple BERT Models for Relation Extraction and Semantic Role Labeling},\n",
      "author={Peng Shi and Jimmy Lin},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1904.05255}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Simple BERT Models for Relation Extraction and Semantic Role Labeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:131773936\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Precision, recall and F1-score\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Ontonotes 5.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = Ontonotes 5.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = 86.49 test F1 on the Ontonotes 5.0 dataset\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = structured-prediction-srl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = srl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Open Information Extraction\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = srl\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = openie-model.2020.03.26.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = structured-prediction/srl.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018).\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Stanovsky et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-03-26\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = BiLSTM\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Stanovsky2018SupervisedOI,\n",
      "title={Supervised Open Information Extraction},\n",
      "author={Gabriel Stanovsky and Julian Michael and Luke Zettlemoyer and I. Dagan},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Supervised Open Information Extraction\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:44145304\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = CoNLL SRL metrics\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = OIE2016, WEB and NYT, PENN\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = The Open Information extractor was evaluated on the OIE2016 corpus. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can get the data on the corpus homepage.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/gabrielStanovsky/oie-benchmark\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = All Words Open IE\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/gabrielStanovsky/supervised-oie/tree/master/data\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = tagging-elmo-crf-tagger\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = crf_tagger\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = ELMo-based Named Entity Recognition\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = ner\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = ner-elmo.2021-02-12.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = tagging/ner_elmo.jsonnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This model is the baseline model described in [Semi-supervised sequence tagging with bidirectional language models](https://api.semanticscholar.org/CorpusID:7197241). It uses a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, and it starts with pretrained GloVe vectors for its token embeddings. It was trained on the CoNLL-2003 NER dataset.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = NER tagger using a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, with GloVe embeddings.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Peters et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-02-10\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = Gated Recurrent Unit (GRU)\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Peters2017SemisupervisedST,\n",
      "title={Semi-supervised sequence tagging with bidirectional language models},\n",
      "author={Matthew E. Peters and Waleed Ammar and Chandra Bhagavatula and R. Power},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Semi-supervised sequence tagging with bidirectional language models\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:7197241\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = CoNLL-2003 NER dataset\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = The NER model was evaluated on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = path/to/dataset\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = CoNLL-2003 NER dataset\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = The NER model was trained on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = /path/to/dataset\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = Achieves 99% accuracy and 96% F1 on the CoNLL-2003 validation set.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = tagging-fine-grained-crf-tagger\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = crf_tagger\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Fine Grained Named Entity Recognition\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = ner\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = fine-grained-ner.2021-02-11.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = tagging/fine-grained-ner.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Lample et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-06-24\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = BiLSTM\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Lample2016NeuralAF,\n",
      "title={Neural Architectures for Named Entity Recognition},\n",
      "author={Guillaume Lample and Miguel Ballesteros and Sandeep Subramanian and K. Kawakami and Chris Dyer},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1603.01360}}\n",
      "\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = Neural Architectures for Named Entity Recognition\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:6042994\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Ontonotes 5.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = Ontonotes 5.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = /path/do/dataset\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 97%\n",
      "F1: 88%\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = tagging-fine-grained-transformer-crf-tagger\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = crf_tagger\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Fine Grained Named Entity Recognition with Transformer\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = ner\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = fgner-transformer.2021-02-11.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = tagging/fgner_transformer.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = Fine-grained NER model\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = Fine-grained NER model\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-07-14\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = Transformer\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Ontonotes 5.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = Ontonotes 5.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 98%\n",
      "F1: 88%\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = ve-vilbert\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = visual-entailment\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = vilbert_ve\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = Visual Entailment\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = ve\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = visual-entailment-torchvision-2020.12.23.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = vilbert_ve_pretrained.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = This model is based on the ViLBERT architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Lu et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = Akshita Bhagia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-12-23\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = ViLBERT based on BERT large\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy and F1-score\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) dev set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) train set\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = This model is trained on the original SNLI-VE dataset. [Subsequent work](https://api.semanticscholar.org/CorpusID:215415945) has found that an estimated 31% of `neutral` labels in the dataset are incorrect. The `e-SNLI-VE-2.0` dataset contains the re-annotated validation and test sets.\n",
      "04/20/2022 13:40:56 - WARNING - allennlp.common.model_card -   visual-entailment is not a registered model.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   id = vqa-vilbert\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_model_name = vqa_vilbert\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_class = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   registered_predictor_name = vilbert_vqa\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   display_name = ViLBERT - Visual Question Answering\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   task_id = vqa\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.archive_file = vilbert-vqa-pretrained.2021-02-11.tar.gz\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.training_config = vision/vilbert_vqa_pretrained.jsonnet\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.developed_by = Lu et al\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.date = 2020-10-01\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.model_type = ViLBERT based on BERT large\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.model_performance_measures = F1-metric and VQA score\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.name = VQA dataset\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = balanced_real_val\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://visualqa.org/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.name = VQA dataset\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.processed_url = balanced_real_train\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.dataset.url = https://visualqa.org/\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 41%\n",
      "VQA: 52%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/20/2022 13:40:56 - WARNING - allennlp.common.model_card -   vqa_vilbert is not a registered model.\n",
      "04/20/2022 13:40:56 - INFO - allennlp.common.plugins -   Plugin allennlp_models available\n",
      "04/20/2022 13:40:57 - INFO - allennlp.common.file_utils -   cache of https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz is up-to-date\n",
      "04/20/2022 13:40:57 - INFO - allennlp.models.archival -   loading archive file https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz from cache at /home/gxu21/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "04/20/2022 13:40:57 - INFO - allennlp.models.archival -   extracting archive file /home/gxu21/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /tmp/tmp0w5zddyy\n",
      "04/20/2022 13:40:59 - INFO - allennlp.common.params -   dataset_reader.type = srl\n",
      "04/20/2022 13:40:59 - INFO - allennlp.common.params -   dataset_reader.max_instances = None\n",
      "04/20/2022 13:40:59 - INFO - allennlp.common.params -   dataset_reader.manual_distributed_sharding = False\n",
      "04/20/2022 13:40:59 - INFO - allennlp.common.params -   dataset_reader.manual_multiprocess_sharding = False\n",
      "04/20/2022 13:40:59 - INFO - allennlp.common.params -   dataset_reader.token_indexers = None\n",
      "04/20/2022 13:40:59 - INFO - allennlp.common.params -   dataset_reader.domain_identifier = None\n",
      "04/20/2022 13:40:59 - INFO - allennlp.common.params -   dataset_reader.bert_model_name = bert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf5d75311f940f28074055dfc02a750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:41:07 - INFO - allennlp.common.params -   dataset_reader.type = srl\n",
      "04/20/2022 13:41:07 - INFO - allennlp.common.params -   dataset_reader.max_instances = None\n",
      "04/20/2022 13:41:07 - INFO - allennlp.common.params -   dataset_reader.manual_distributed_sharding = False\n",
      "04/20/2022 13:41:07 - INFO - allennlp.common.params -   dataset_reader.manual_multiprocess_sharding = False\n",
      "04/20/2022 13:41:07 - INFO - allennlp.common.params -   dataset_reader.token_indexers = None\n",
      "04/20/2022 13:41:07 - INFO - allennlp.common.params -   dataset_reader.domain_identifier = None\n",
      "04/20/2022 13:41:07 - INFO - allennlp.common.params -   dataset_reader.bert_model_name = bert-base-uncased\n",
      "04/20/2022 13:41:08 - INFO - allennlp.common.params -   type = from_instances\n",
      "04/20/2022 13:41:08 - INFO - allennlp.data.vocabulary -   Loading token dictionary from /tmp/tmp0w5zddyy/vocabulary.\n",
      "04/20/2022 13:41:08 - INFO - allennlp.common.params -   model.type = srl_bert\n",
      "04/20/2022 13:41:08 - INFO - allennlp.common.params -   model.regularizer = None\n",
      "04/20/2022 13:41:08 - INFO - allennlp.common.params -   model.bert_model = bert-base-uncased\n",
      "04/20/2022 13:41:08 - INFO - allennlp.common.params -   model.embedding_dropout = 0.1\n",
      "04/20/2022 13:41:08 - INFO - allennlp.common.params -   model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f2b3919f910>\n",
      "04/20/2022 13:41:08 - INFO - allennlp.common.params -   model.label_smoothing = None\n",
      "04/20/2022 13:41:08 - INFO - allennlp.common.params -   model.ignore_span_metric = False\n",
      "04/20/2022 13:41:08 - INFO - allennlp.common.params -   model.srl_eval_path = /home/gxu21/anaconda3/envs/newECONET/lib/python3.8/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -   Initializing parameters\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -   Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.embeddings.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.embeddings.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.embeddings.position_embeddings.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.embeddings.token_type_embeddings.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.embeddings.word_embeddings.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.intermediate.dense.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.key.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.key.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.query.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.query.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.value.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.value.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.intermediate.dense.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.pooler.dense.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      bert_model.pooler.dense.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      tag_projection_layer.bias\n",
      "04/20/2022 13:41:10 - INFO - allennlp.nn.initializers -      tag_projection_layer.weight\n",
      "04/20/2022 13:41:10 - INFO - allennlp.models.archival -   removing temporary unarchived model dir at /tmp/tmp0w5zddyy\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from utils import * \n",
    "from get_srl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c5723a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the triggers: ---------  \n",
      "\n",
      "hated bomb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rel_type': 'BEFORE',\n",
       " 'rev': None,\n",
       " 'doc_dictionary': OrderedDict([('[0:1)', ('I', None)),\n",
       "              ('[2:7)', ('hated', None)),\n",
       "              ('[8:13)', ('going', None)),\n",
       "              ('[14:16)', ('to', None)),\n",
       "              ('[17:23)', ('school', None)),\n",
       "              ('[23:24)', (';', None)),\n",
       "              ('[25:27)', ('so', None)),\n",
       "              ('[27:28)', (',', None)),\n",
       "              ('[29:30)', ('i', None)),\n",
       "              ('[31:35)', ('will', None)),\n",
       "              ('[36:40)', ('bomb', None)),\n",
       "              ('[41:43)', ('my', None)),\n",
       "              ('[44:50)', ('school', None)),\n",
       "              ('[50:51)', ('!', None))]),\n",
       " 'event_labels': None,\n",
       " 'doc_id': None,\n",
       " 'left_event': <utils.Event at 0x7f2c9c4a2a00>,\n",
       " 'right_event': <utils.Event at 0x7f2b391863d0>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sent = \"I hated going to school; so, i will bomb my school!\"\n",
    "\n",
    "\n",
    "def parse(sent, event1_id, event2_id):\n",
    "    od = OrderedDict()\n",
    "    \n",
    "    events = get_predicate(sent)\n",
    "#     if not events:\n",
    "#         continue\n",
    "    tokens = events[0][-1]\n",
    "    print(\"print the triggers: ---------  \\n\")\n",
    "    print(tokens[event1_id], tokens[event2_id])\n",
    "    tok_id = 0\n",
    "    event1_span, event2_span = None, None\n",
    "    for offset in range(len(sent)):\n",
    "        if tok_id ==event1_id:\n",
    "            event1_span = (offset, offset+len(tokens[tok_id])-1)\n",
    "        elif tok_id ==event2_id:\n",
    "            event2_span = (offset, offset+len(tokens[tok_id])-1)\n",
    "        if tok_id >= len(tokens):\n",
    "            break\n",
    "        tok = tokens[tok_id]\n",
    "        if sent[offset:offset+len(tok)]==tok:\n",
    "            od['['+str(offset)+':'+str(offset+len(tok)) + ')'] = (tok, None)\n",
    "            tok_id+=1\n",
    "    return od, event1_span, event2_span\n",
    "\n",
    "\n",
    "\n",
    "def create_data_instance(sent, event1_id, event2_id):\n",
    "    \"\"\"\n",
    "    sentence is a string and event spans are a list of the spans of two events\n",
    "    event1_id, event2_id are positional token id of the two event trigger tokens\n",
    "    \"\"\" \n",
    "    doc_dict,e1_span,e2_span = parse(sent, event1_id, event2_id)\n",
    "    left_event = Event(None, None, None, None, None, e1_span)\n",
    "    right_event = Event(None, None, None, None, None, e2_span)\n",
    "    v = dict()\n",
    "    v['rel_type'],v['rev'],v['doc_dictionary'],v['event_labels'],v['doc_id'],v['left_event'],v['right_event'] = \\\n",
    "    'BEFORE', None, doc_dict, None, None, left_event, right_event\n",
    "    return v\n",
    "\n",
    "\n",
    "def create_data_instances(sents, event_ids):\n",
    "    cnt = 0 \n",
    "    d = dict()\n",
    "    for sent, event_id, verb in zip(sents, event_ids, verbs):\n",
    "        v = create_data_instance(sent, event_id[0], event_id[1])\n",
    "        d['L_' + str(cnt)] = v\n",
    "        cnt+=1\n",
    "    return d\n",
    "        \n",
    "create_data_instance(sent,1,10)\n",
    "\n",
    "# parse(sent)\n",
    "# examples = create_data_instance(sent, event_spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d745a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = create_data_instances(sents, event_spans_ls)\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81aa5ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the triggers: ---------  \n",
      "\n",
      "hated bomb\n"
     ]
    }
   ],
   "source": [
    "a = create_data_instance(sent,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f339dfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['left_event'].span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f87ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
